from index.extractor import Extractor
from index.splitter import Splitter
from index.vector_store import VectorStoreService
from index.llm_service import LLMService
from langchain_core.documents import Document
from typing import List, Optional

class IndexService:
    """Servicio de indexaciÃ³n OPTIMIZADO que sigue la documentaciÃ³n de LangChain."""

    def __init__(self, embedding_model: str = None):
        print("ğŸš€ Inicializando IndexService optimizado...")
        
        self.extractor = Extractor()
        self.splitter = Splitter()
        self.vector_store_service = VectorStoreService(embedding_model_name=embedding_model)
        self.llm_service = LLMService()
        
        print("ğŸ”Œ Conectando a Pinecone...")
        if self.vector_store_service.create_index_if_not_exists():
            print("âœ… ConexiÃ³n a Pinecone establecida")
        else:
            print("âŒ Error conectando a Pinecone")

    def index_pipeline(self, url: str = None, content: str = None) -> bool:
        """Pipeline OPTIMIZADO siguiendo la documentaciÃ³n de LangChain."""
        try:
            print("=== PIPELINE DE INDEXACIÃ“N OPTIMIZADO ===")
            
            if url:
                print("ğŸ“¥ PASO 1: Extrayendo contenido de URL...")
                content = self.extractor.extract_md(url)
                print("âœ… ExtracciÃ³n completada")
            elif content:
                print("ğŸ“„ PASO 1: Usando contenido proporcionado...")
            else:
                print("âŒ Debe proporcionar URL o contenido")
                return False
            
            print("âœ‚ï¸  PASO 2: Dividiendo contenido en chunks...")
            chunks = self.splitter.split_md(content)
            
            if not chunks:
                print("âŒ No se generaron chunks")
                return False
            
            print(f"ğŸ“‹ Generados {len(chunks)} chunks como Document objects")
            
            print("ğŸš€ PASO 3: Indexando usando add_documents()...")
            success = self.vector_store_service.add_documents(chunks)
            
            if success:
                print("âœ… Pipeline completado exitosamente")
                stats = self.vector_store_service.get_index_stats()
                if 'total_vectors' in stats:
                    print(f"ğŸ“Š Total de vectores: {stats['total_vectors']}")
                return True
            else:
                print("âŒ Error en la indexaciÃ³n")
                return False
                
        except Exception as e:
            print(f"âŒ Error en pipeline: {e}")
            return False

    def search(self, query: str, top_k: int = 10) -> List[dict]:
        try:
            return self.vector_store_service.search_similar(query, top_k)
        except Exception as e:
            print(f"âŒ Error en bÃºsqueda: {e}")
            return []

    def rag_query(self, question: str, top_k: int = 10) -> str:
        try:
            relevant_docs = self.search(question, top_k)
            
            if not relevant_docs:
                return "No se encontrÃ³ informaciÃ³n relevante."
            
            context = "\n\n".join([doc['content'] for doc in relevant_docs])
            response = self.llm_service.generate_response(question, context)
            
            return response
        except Exception as e:
            return f"Error procesando la consulta: {str(e)}"

    def get_stats(self) -> dict:
        return self.vector_store_service.get_index_stats()

    def delete_index(self) -> bool:
        return self.vector_store_service.delete_index()

    def index_documents(self, documents: List[Document]) -> bool:
        try:
            return self.vector_store_service.add_documents(documents)
        except Exception as e:
            print(f"âŒ Error indexando documentos: {e}")
            return False

    def index_texts(self, texts: List[str], metadatas: List[dict] = None) -> bool:
        try:
            documents = []
            for i, text in enumerate(texts):
                metadata = metadatas[i] if metadatas and i < len(metadatas) else {}
                doc = Document(page_content=text, metadata=metadata)
                documents.append(doc)
            
            return self.vector_store_service.add_documents(documents)
        except Exception as e:
            print(f"âŒ Error indexando textos: {e}")
            return False
